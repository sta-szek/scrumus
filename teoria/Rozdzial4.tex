\chapter{Dokumentacja wdrożeniowa i testowa}
W tym rozdziale opiszę proces budowania projektu z zastosowaniem specjalnie przeznaczonego do tego celu systemu Gradle. Następnie prześledzimy przebieg wdrażania z wykorzystaniem kontenerów Dockerów, a na końcu przedstawię statystyki oraz wyniki testów projektu.

\section{Gradle}
We wcześniejszych rozdziałach został opisany system Gradle, który jest używany podczas budowy projektu wytwarzanego w ramach pracy dyplomowej. Skupię się tutaj na opisaniu komend użytecznych podczas pracy z kodem oraz przedstawię wyniki uruchomienia budowy na lokalnym serwerze TeamCity.

Na początek jednak pragnę przedstawić tabelę porównawczą systemu Gradle oraz Maven\footnote{Wyczerpujące porównanie wybranych systemów można znaleźć pod adresem \url{http://gradle.org/maven_vs_gradle/}}, w celu lepszego zobrazowania wyboru oraz zachęcenia do korzystania z tegoż frameworka. Wyniki zostały zawarte w tabeli \ref{tabela:gradle_vs_maven}.

\begin{table}[h!]
	\caption{Porównanie systemu Gradle vs Maven}
	\centering
	\begin{tabular}{|c|c|c|}
		\hline
		& Gradle & Maven \\
		\hline
		\specialcell{Liczba linii w pliku konfiguracyjnym\\ systemu scrumus} & 54 & 150 \\
		\hline		
		Wykonywanie zadań & Tak & Niemożliwe bez dodatków \\
		\hline		
		Graficzny interfejs użytkownika & Tak (opcja -gui) & Nie \\
		\hline		
		\specialcell{Automatycznie wykrywanie zmian\\ i budowanie projektu} & Tak & Nie \\
		\hline	
		Dynamiczne zależności & Tak & Nie \\
		\hline	
		Rozwiązywanie konfliktów zależności & Tak & Nie \\
		\hline	
		Przyrostowe budowanie & Tak & Nie \\
		\hline	
		Deamon & Tak & Nie \\
		\hline	
		Równoległe wykonywanie zadań & Tak & Nie \\
		\hline	
	\end{tabular}
	\label{tabela:gradle_vs_maven}
\end{table}

System Gradle rozpoczyna budowę projektu po uruchomieniu komendy:

\verb|gradle build|

Istnieje też możliwość definiowania własnych zadań oraz uruchamiania ich po kolei. Przykładowe wywołanie zadań: zbuduj, przetestuj jednostkowo, przetestuj integracyjnie, wgraj na serwer można uruchomić za pomocą komendy:


\verb|gradle build test integrationTest deploy|

Projekt wytworzony podczas pracy dyplomowej korzystał z lokalnego serwera do budowy projektów jakim jest TeamCity. W celu wykonania budowy została użyta komenda \verb|gradle clean build|, która dawała następujące wyniki:

\begin{verbatim}
	[20:20:00]Skip checking for changes - changes are already collected
	[20:20:00]Clearing temporary directory: E:\study\TeamCity\buildAgent\temp\buildTmp
	[20:20:00]Publishing internal artifacts
	[20:20:00]Checkout directory: E:\study\TeamCity\buildAgent\work\2166da533cb64e16
	[20:20:00]Updating sources: server side checkout
	[20:20:00][Updating sources] Using vcs information from agent ...
	[20:20:00][Updating sources] Building incremental patch for VCS root:...
	[20:20:01][Updating sources] Repository sources transferred: 36.14 KB total
	[20:20:01][Updating sources] Updating E:\study\TeamCity\buildAgent\work\2166da533cb64e16
	[20:20:01]Step 1/1: Gradle (7m:31s)
	[20:20:01][Step 1/1] Starting: "C:\Program Files\gradle-2.6\bin\gradle.bat" ...
	[20:20:01][Step 1/1] in directory: E:\study\TeamCity\buildAgent\work\2166da533cb64e16
	[20:20:03][Step 1/1] Starting Gradle in TeamCity build 174
	[20:20:03][Step 1/1] :clean
	[20:20:04][Step 1/1] :compileJava (2s)
	[20:20:07][Step 1/1] :processResources
	[20:20:07][Step 1/1] :classes
	[20:20:07][Step 1/1] :war
	[20:20:07][Step 1/1] :assemble
	[20:20:08][Step 1/1] :compileTestJava (1s)
	[20:20:10][Step 1/1] :processTestResources
	[20:20:10][Step 1/1] :testClasses
	[20:20:10][Step 1/1] :test (7m:22s)
	[20:27:32][Step 1/1] :check
	[20:27:32][Step 1/1] :build
	[20:27:32][Step 1/1] 
	[20:27:32][Step 1/1] BUILD SUCCESSFUL
	[20:27:32][Step 1/1] 
	[20:27:32][Step 1/1] Total time: 7 mins 30.796 secs
	[20:27:32][Step 1/1] Process exited with code 0
	[20:27:32]Publishing artifacts
	[20:27:32]Publishing artifacts
	[20:27:32]Publishing artifacts
	[20:27:32]Generating coverage report...
	[20:27:33]Calculating coverage statistics...
	[20:27:33]Publishing internal artifacts
	[20:27:33]Build finished
\end{verbatim}

Jak widać, na załączonym powyżej logu z historii budowy, system TeamCity po dostaniu sygnału o zmianie stanu repozytorium zdalnego (zawartego na GitHubie) rozpoczął proces aktualizacji źródeł. Następnie po transferze wykonała się komenda Gradle uruchamiająca budowę projektu. W skład tej fazy wchodzą następująco:
\begin{itemize}
	\item \textbf{clean} - wyczyszczenie folderu wynikowego,
	\item \textbf{compileJava} - kompilacja źródeł Java używając kompilatora javac,
	\item \textbf{processResources} - kopiowanie plików produkcyjnych zasobów do folderu docelowego,
	\item \textbf{classes} - gromadzenie klas produkcyjnych i folderów produkcyjnych zasobów,
	\item \textbf{war} - gromadzenie zasobów WAR,
	\item \textbf{assemble} - gromadzenie wszystkich archiwów w projekcie,
	\item \textbf{compileTestJava} - kompilacja źródeł testowych Java używając kompilatora javac,
	\item \textbf{processTestResources} - kopiowanie plików testowych zasobów do folderu docelowego,
	\item \textbf{testClasses} - gromadzenie klas testowych i folderów testowych zasobów,
	\item \textbf{test} - uruchomienie testów jednostkowych oraz integracyjnych,
	\item \textbf{check} - uruchomienie wszystkich zadań weryfikujących,
	\item \textbf{build} - wykonanie pełnej budowy projektu.
\end{itemize}

Po wykonaniu wszystkich wyżej wymienionych zadań dostajemy informację o powodzeniu zakończenia budowy projektu, co oznacza, że wszystkie testy przeszły oraz nie wystąpił błąd podczas żadnej fazy budowy. Na końcu system TeamCity publikuje wyniki testów -- udostępnia je samemu sobie, tak aby były możliwe do wyświetlenia na stronie.

\section{Docker}
Docker jest kolejnym systemem użytym podczas wytwarzania pracy dyplomowej. Służy on do pakowania aplikacji w gotowe jednostki uruchomieniowe. Jego podstawowymi koncepcjami jest utrzymanie zawsze stabilnej, niezmiennej paczki aplikacji, którą da się bez problemu uruchomić na każdym systemie rodziny UNIX zawierającym oprogramowanie Docker.

Obrazy systemów są tworzone z plików \textit{Dockerfile}, które opisują jakie oprogramowanie ma zostać wgrane w dany obraz. Następnie definiujemy zmienne środowiskowe oraz komendy, które mają zostać uruchomione podczas budowania obrazu. Po tych czynnościach następuje deklaracja co ma zostać wykonane po starcie kontenera.

Każdy obraz podczas swojego powstawania tworzy tzw. między obrazy. Są to obrazy, które powstają po wykonaniu komend modyfikujących aktualny obraz. Najlepiej wyjaśnić to na przykładzie:

\begin{enumerate}
	\item W pliku Dockerfile definiujemy z jakiego obrazu ma powstać nasz, np. z obrazu systemu ubuntu. W tym momencie powstaje pierwszy między obraz.
	\item Po wgraniu systemu ubuntu "mówimy" Dockerowi, aby zaaktualizował nasz system. Po tej aktualizacji system utworzy kolejny między obraz z wgranymi aktualizacjam.
	\item Kolejnym krokiem będzie zainstalowanie np. bazy danych. Po jej instalacji zostanie wygenerowany kolejny między obraz itd.
\end{enumerate}

Głównym powodem, który zadecydował o wybraniu tej technologii była jej łatwość użycia i możliwość uruchomienia systemu scrumus, mając jedynie kilkunastolinijkowy plik konfiguracyjny. Na listingu \ref{lis:dockerfile} został przedstawiony plik Dockerfile systemu scrumus.

\begin{lstlisting}[caption={Plik Dockerfile systemu scrumus}, label=lis:dockerfile, numbers=none]
FROM jboss/wildfly

USER root

ENV HOME /opt/jboss
ENV JBOSS_HOME /opt/jboss/wildfly

RUN yum install -y \
postgresql \
postgresql-contrib \
pgadmin3 \
telnet \
curl

RUN /opt/jboss/wildfly/bin/add-user.sh admin admin --silent

COPY /postgresql /opt/jboss/wildfly/modules/system/layers/base/org/postgresql

EXPOSE 9990:9990 8080:8080

CMD ["/opt/jboss/wildfly/bin/standalone.sh", 
			"-b", "0.0.0.0", 
			"-bmanagement", "0.0.0.0"]\end{lstlisting}

W przedstawionym wyżej listingu tworzymy obraz Dockera oparty na obrazie \textit{jboss/wildfly}, co mówi klauzula \textit{FROM}. Następnie przełączamy się na użytkownika \textit{root} i ustawiamy dwie zmienne środowiskowe za pomocą komendy \textit{ENV}. Kolejnym krokiem jest aktualizacja systemu oraz zainstalowanie bazy danych Postgresql i skryptu telnet, który jest przydatny przy sprawdzaniu poprawności działania systemu. Następnie tworzymy użytkownika o nazwie \textit{admin}. Po tych operacjach kopiujemy konfigurację bazy zawartą w folderze \textit{postgres}, wystawiamy porty na zewnątrz kontenera. Komenda \textit{CMD} mówi nam, co ma się wykonać po uruchomieniu kontenera. W naszym przypadku jest to uruchomienie serwera wildfly w wersji standalone, na której uprzednio skonfigurowany został system scrumus.

\section{Wyniki testów}
Kolejnym, a zarazem ostatnim elementem jakie zostaną opisane w pracy dyplomowej będzie opis testów jednostkowych i integracyjnych. Podczas pisania testów korzystano z konwencji \textit{given-when-then}, czyli mając (given) wartości, kiedy (when) wykonana zostanie dana operacje, wtedy (then) upewnij się, że coś się zgadza lub coś się wykonało. Zostaną również przedstawione wyniki pokrycia kodu oraz krótkie statystyki dot. projektu.

\subsection{Testy jednostkowe}
W pracy do jednostkowego przetestowania kodu użyto frameworka JUnit wspartego kolejną biblioteką do "podszywania się obiektów" (\textit{ang. mocking objects}) PowerMockito. Testy jednostkowe stosuje się, jak sama nazwa mówi, do przetestowania jednostkowej funkcjonalności np. dodawania liczb, generowania ciągu znaków czy wywoływania metod. W celu poprawy czytelności kodu zastosowano funkcje projektu AssertJ ułatwiającego asercje z bogatym wsparciem dla list, obiektów \textit{Optional} czy strumieni z Java 8. Kod przykładowego testu został przedstawiony na listingu \ref{lis:unit}.

\begin{lstlisting}[caption={Kod przykładowego testu jednostkowego}, label=lis:unit, numbers=none]
@Test
public void shouldEncodeWithSHA256() throws Exception {
// given
String stringToHash = "123";
String expectedHash = "a665a45920422f9d417e4867efdc4fb8a04"
										+ "a1f3fff1fa07e998e86f7f7a27ae3";
HashGenerator hashGenerator = new HashGenerator();

// when
String result = hashGenerator.encodeWithSHA256(stringToHash);

// then
assertThat(result).isEqualTo(expectedHash);
}\end{lstlisting}

\subsection{Testy integracyjne}
Następnym rodzajem testów były testy integracyjne, które w odróżnieniu od jednostkowych służą do sprawdzenia integracji, czyli współpracy różnych komponentów systemu. Istnieją różne interpretacje testów integracyjnych - niektóre z nich mówią, że są to bardziej rozbudowane testy jednostkowe, które nadal nie mogą korzystać z zewnętrznych źródeł, inne zaś, iż komunikacja z np. bazą danych jest dozwolona. 

W pracy zastosowano podejście, które umożliwia komunikację z bazą danych. Dzięki temu mogło zostać przetestowane również mapowanie się obiektów na struktury oraz zachowanie się JPA podczas próby wprowadzenia błędnych danych, które nie zawsze były oczywiste.

Testy integracyjne korzystają z frameworku Arquillian, który jak wcześniej opisano pozwala tworzyć pliki wdrożeniowe i uruchamiać je na serwerach wbudowanych, lokalnych oraz zdalnych. Przykład utworzenia testowego pliku wdrożenia został przedstawiony na listingu \ref{lis:arqu}.

\begin{lstlisting}[caption={Przykład przygotowania pliku wdrożenia Arquillian}, label=lis:arqu, numbers=none]
 public static WebArchive createDeployment() {
		 return ShrinkWrap.create(WebArchive.class, "test.war")
										  .addPackages(true, "edu.piotrjonski.scrumus")
										  .addPackages(true, "org.assertj.core")
									   	.addPackages(true, "org.mockito")
										  .addPackages(true, "org.objenesis")
										  .addPackages(true, "org.apache.commons.collections4")
										  .addAsResource("META-INF/persistence.xml")
										  .addAsResource("configuration.properties")
										  .as(WebArchive.class);
 }\end{lstlisting}

Przedstawiony wyżej listnig tworzy plik WAR oraz dodaje rekurencyjnie do niego pakiety znajdujące się w pakietach: edu.piotrjonski.scrumus, org.assertj.core, org.mockito, org.obejnesis, org.apache.commons.collections4. Dodatkowo kopiowane są pliki ustawień bazy danych - persistence.xml oraz plik konfiguracji systemu. Wszystko jest wdrażane pod nazwą test.war.

Na listingu \ref{lis:integ} przedstawiono przykładowy test integracyjny. W pierwszej kolejności tworzone są dwa nowe zadania, które następnie zostają zapisane w bazie danych za pomocą obiektu DAO. Obiekt DAO został wstrzyknięty (\textit{ang. injected}) do klasy testu, co było możliwe dzięki uruchomieniu testu w kontenerze. Kolejnym krokiem jest wyszukanie zadań z odpowiednim statusem - to właśnie metoda o nazwie \textit{findAllIssuesWithIssueType} jest tutaj testowana. Na końcu następuje sprawdzenie, czy zwrócona lista zawiera dwa elementy.

\begin{lstlisting}[caption={Przykład testu integracyjnego}, label=lis:integ, numbers=none]
@Test
public void shouldFindAllIssuesWithGivenIssueType() {
// given
Issue issue1 = createIssue();
Issue issue2 = createIssue();
issueDAO.saveOrUpdate(issue1);
issueDAO.saveOrUpdate(issue2);

// when
List<Issue> result = issueDAO.findAllIssuesWithIssueType(issue1.getIssueType()
.getName());

// then
assertThat(result).hasSize(2);
}\end{lstlisting}


\subsection{Podsumowanie wyników testów oraz statystyki}
Projekt został oparty na wielu różnych frameworkach dedykowanych językowi Java oraz z użyciem komponentów wspierających ciągłą integrację i wdrażanie systemu.

Podczas pracy napisano 103 (składających się z 2774 linii kodu) testy jednostkowe oraz 261 testów integracyjnych, które zawierają 7285 linii kodu. Kod produkcyjny jest złożony z 6349 linii, które zostały zoptymalizowane dzięki wykorzystaniu wzorców. 

Łącznie napisano 16428 linii kodu Javy, 2137 xhtml, 1086 \LaTeX, 292 xml oraz 83 css, co daje 20026 powodów do radości.  Sumaryczny czas wytworzenia projektu, wraz z częścią teoretyczną, wyniósł 98 dni. W tym czasie rozwiązano 43 zadania, wykonano 196 zdalnych budowań projektów oraz 262 commity, co daje około 204 linie kodu, 0.4 zadania, 2 budowy projektu i 2.7 commita dziennie.

Kolejnym faktem jest, iż w aplikacji stosowano języka Java w wersji 8 oraz wykorzystywano wszystkie jego mechanizmy takie jak strumienie czy Optionale. Dzięki Optionalom w kodzie produkcyjnym nie ma ani jednego słówka kluczowego \textbf{null}, a przynajmniej w całej logice biznesowej.

Łączne pokrycie kodu nie przekracza poziomu 72\% klas 43\% metod i 32\% linii kodu. Taki wynik jest dalece rozbieżny z prawdą przez problemy z kompatybilnością frameworku Arquillian, PowerMockito oraz narzędzia mierzącego pokrycie kodu jakim jest IntelliJ Code Coverage Runner. Spowodowane jest to tworzeniem obiektów proxy przez Arquilliana, przez co pokrycie wywoływanych metod nie jest w pełni mierzone. Inne narzędzia służące do pomiaru takie jak JaCoCo czy Cobertura również miały z tym faktem problemy.
